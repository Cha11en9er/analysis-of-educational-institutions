# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ --------------------------------
import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
from collections import Counter
import re
from sklearn.feature_extraction.text import TfidfVectorizer
import seaborn as sns
import json
import os

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON —Ñ–∞–π–ª–∞
input_file = os.path.join(os.path.dirname(__file__), '..', 'fa_data', 'fa_input', 'fa_input_data_id_3.json')
with open(input_file, 'r', encoding='utf-8') as f:
    data = json.load(f)

# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ DataFrame
df = pd.DataFrame(data['reviews'])  # –≤–∞—à–∏ –æ—Ç–∑—ã–≤—ã

# –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç
df['date'] = pd.to_datetime(df['date'])
df['year_month'] = df['date'].dt.to_period('M')
df['year'] = df['date'].dt.year

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è tonality –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
tonality_map = {'–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π': 1, '–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π': -1, '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π': 0, '–°—Ä–µ–¥–Ω–∏–π': 0}
df['sentiment_score'] = df['tonality'].map(tonality_map)
# –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ --------------------------------

# —Å—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ –º–µ—Å—è—Ü–∞–º --------------------------------
monthly_stats = df.groupby('year_month').agg({
    'rating': ['mean', 'count'],
    'sentiment_score': 'mean',
    'likes_count': 'mean'
}).round(2)

monthly_stats.columns = ['avg_rating', 'review_count', 'avg_sentiment', 'avg_likes']
monthly_stats['avg_rating'] = monthly_stats['avg_rating'].fillna(0)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))

monthly_stats['avg_rating'].plot(ax=ax1, marker='o', linewidth=2)
ax1.set_title('–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ –º–µ—Å—è—Ü–∞–º')
ax1.grid(True)

monthly_stats['avg_sentiment'].plot(ax=ax2, marker='s', linewidth=2, color='red')
ax2.set_title('–°—Ä–µ–¥–Ω—è—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –æ—Ç–∑—ã–≤–æ–≤ (1=–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è, -1=–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è)')
ax2.grid(True)

plt.tight_layout()
plt.show()
# —Å—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ –º–µ—Å—è—Ü–∞–º --------------------------------

# –ê–Ω–∞–ª–∏–∑ —Ç–µ–º main_idea –ø–æ –º–µ—Å—è—Ü–∞–º --------------------------------
def extract_keywords(texts, top_n=10):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ main_idea"""
    # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –º–µ–Ω—å—à–µ 2, –∏—Å–ø–æ–ª—å–∑—É–µ–º min_df=1
    min_df_value = min(2, max(1, len(texts) - 1)) if len(texts) > 1 else 1
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç—ã
    texts_filtered = [str(text).strip() for text in texts if str(text).strip()]
    
    if len(texts_filtered) == 0:
        return []
    
    try:
        vectorizer = TfidfVectorizer(max_features=100, stop_words='english', 
                                    ngram_range=(1,2), min_df=min_df_value)
        tfidf_matrix = vectorizer.fit_transform(texts_filtered)
        feature_names = vectorizer.get_feature_names_out()
        
        if len(feature_names) == 0:
            return []
        
        # –°—Ä–µ–¥–Ω–∏–π TF-IDF score –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
        mean_scores = np.mean(tfidf_matrix.toarray(), axis=0)
        top_indices = mean_scores.argsort()[-top_n:][::-1]
        
        return [(feature_names[i], mean_scores[i]) for i in top_indices]
    except ValueError:
        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –æ—à–∏–±–∫–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        return []

# –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º
monthly_themes = df.groupby('year_month')['main_idea'].apply(list).reset_index()

themes_evolution = []
for idx, row in monthly_themes.iterrows():
    month = row['year_month']
    texts = row['main_idea']
    if len(texts) > 0:
        keywords = extract_keywords(texts, top_n=8)
        themes_evolution.append({
            'month': month,
            'review_count': len(texts),
            'top_themes': keywords[:5]
        })

themes_df = pd.DataFrame(themes_evolution)
# –∞–Ω–∞–ª–∏–∑ —Ç–µ–º main_idea –ø–æ –º–µ—Å—è—Ü–∞–º --------------------------------

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–º + –≤—Ä–µ–º–µ–Ω–Ω–∞—è —ç–≤–æ–ª—é—Ü–∏—è --------------------------------
# –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–µ–º
theme_categories = {
    '—Ä–µ–º–æ–Ω—Ç': ['—Ä–µ–º–æ–Ω—Ç', '—Å—Ç–µ–Ω—ã', '—Ç—Ä–µ—â–∏–Ω—ã', '—Ç—É–∞–ª–µ—Ç', '–º–æ–∑–∞–∏–∫', '–∞—Å—Ñ–∞–ª—å—Ç'],
    '—É—á–∏—Ç–µ–ª—è': ['—É—á–∏—Ç–µ–ª—å', '–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å', '–ø–µ–¥–∞–≥–æ–≥', '–∫–ª–∞—Å—Å–Ω—ã–π'],
    '–µ–¥–∞': ['–µ–¥–∞', '–∫–æ—Ä–º', '—Å—Ç–æ–ª–æ–≤–∞—è', '–ø–∏—Ç–∞–Ω–∏–µ', '–æ—Ç—Ä–∞–≤'],
    '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è': ['–¥–∏—Ä–µ–∫—Ç–æ—Ä', '–∑–∞–≤—É—á', '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å'],
    '–±—É–ª–ª–∏–Ω–≥': ['—Ç—Ä–∞–≤–ª—è', '–±—É–ª–ª–∏–Ω–≥', '–æ–±–∏–∂', '–±—å—é—Ç'],
    '–∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞': ['–ø–∞—Ä–∫–æ–≤–∫', '–º–µ—Å—Ç–æ', '–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤', '–∫–ª–∞—Å—Å']
}

def categorize_themes(main_idea, categories):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è main_idea –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
    main_idea_lower = main_idea.lower()
    cat_scores = {}
    for cat, keywords in categories.items():
        score = sum(1 for kw in keywords if kw in main_idea_lower)
        cat_scores[cat] = score
    return cat_scores

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ –¥–∞–Ω–Ω—ã–º
df['theme_scores'] = df['main_idea'].apply(lambda x: categorize_themes(x, theme_categories))

# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –¥–ª–∏–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
theme_evolution = []
for idx, row in df.iterrows():
    for theme, score in row['theme_scores'].items():
        if score > 0:
            theme_evolution.append({
                'date': row['date'],
                'year_month': row['year_month'],
                'theme': theme,
                'sentiment': row['sentiment_score'],
                'rating': row['rating'],
                'likes': row['likes_count']
            })

theme_df = pd.DataFrame(theme_evolution)
monthly_theme_trends = theme_df.groupby(['year_month', 'theme']).agg({
    'rating': 'mean',
    'sentiment': 'mean',
    'likes': 'mean'
}).reset_index()
# –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–º + –≤—Ä–µ–º–µ–Ω–Ω–∞—è —ç–≤–æ–ª—é—Ü–∏—è --------------------------------

# —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ç–µ–º –ø–æ –º–µ—Å—è—Ü–∞–º --------------------------------
pivot_sentiment = monthly_theme_trends.pivot(
    index='year_month', columns='theme', values='sentiment'
).fillna(0)

plt.figure(figsize=(14, 8))
sns.heatmap(pivot_sentiment, annot=True, cmap='RdYlGn', center=0, 
            fmt='.2f', cbar_kws={'label': '–°—Ä–µ–¥–Ω—è—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å'})
plt.title('–≠–≤–æ–ª—é—Ü–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–º –ø–æ –º–µ—Å—è—Ü–∞–º')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
# —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ç–µ–º –ø–æ –º–µ—Å—è—Ü–∞–º --------------------------------

# –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–º –ø–æ –º–µ—Å—è—Ü–∞–º plotly --------------------------------
from scipy.stats import zscore
from sklearn.linear_model import LinearRegression

# –î–µ—Ç–µ–∫—Ü–∏—è —Ä–µ–∑–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ
monthly_stats['rating_zscore'] = zscore(monthly_stats['avg_rating'].fillna(0))

# –ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ —Ç–æ—á–µ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π (–∞–Ω–æ–º–∞–ª–∏–π)
change_points = monthly_stats[abs(monthly_stats['rating_zscore']) > 1.5]

print("–¢–æ—á–∫–∏ —Ä–µ–∑–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π:")
print(change_points[['avg_rating', 'review_count', 'avg_sentiment']])

# –ê–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–æ–≤ –≤ —Ç–æ—á–∫–∞—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
for idx, cp in change_points.iterrows():
    month_reviews = df[df['year_month'] == cp.name]
    print(f"\n=== {cp.name} ===")
    print("–¢–æ–ø main_idea:")
    print(month_reviews['main_idea'].value_counts().head())
# –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–º –ø–æ –º–µ—Å—è—Ü–∞–º plotly --------------------------------

# —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç --------------------------------
def generate_summary():
    summary = f"""
    üìä –ê–ù–ê–õ–ò–ó –û–¢–ó–´–í–û–í –®–ö–û–õ–´ ‚Ññ2
    
    –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
    ‚Ä¢ –í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤: {len(df)}
    ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {df['rating'].mean():.1f}
    ‚Ä¢ –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö: {len(df[df['sentiment_score']==1])} ({len(df[df['sentiment_score']==1])/len(df)*100:.0f}%)
    
    üïí –ö–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã:
    """
    
    # –¢–æ–ø –∏–∑–º–µ–Ω–µ–Ω–∏—è
    recent_trend = monthly_stats['avg_rating'].iloc[-6:].mean() - monthly_stats['avg_rating'].iloc[:-6].mean()
    summary += f"‚Ä¢ –¢—Ä–µ–Ω–¥ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6–º: {'üìà —É–ª—É—á—à–µ–Ω–∏–µ' if recent_trend>0 else 'üìâ —É—Ö—É–¥—à–µ–Ω–∏–µ'} –Ω–∞ {recent_trend:.1f} –±–∞–ª–ª–æ–≤"
    
    # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–º—ã
    all_themes = Counter()
    for ideas in df['main_idea'].str.split(',').tolist():
        all_themes.update([idea.strip() for idea in ideas if idea.strip()])
    
    summary += f"\n‚Ä¢ –¢–æ–ø —Ç–µ–º—ã: {dict(all_themes.most_common(5))}"
    
    print(summary)

generate_summary()
# —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç --------------------------------